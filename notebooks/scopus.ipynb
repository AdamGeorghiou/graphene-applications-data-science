{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Scopus data collection...\n",
      "Searching Scopus for: graphene applications\n",
      "Using API key: 4bbbd...\n",
      "\n",
      "Fetching batch 1 (records 1 to 25)...\n",
      "Found 25 papers in this batch (Total available: 94883)\n",
      "Collected: Three different methods for ZnO-RGO nanocomposite synthesis and its adsorption capacity for methylen...\n",
      "Collected: Zinc oxide nanoparticles decorated nitrogen doped porous reduced graphene oxide-based hybrid to sens...\n",
      "Collected: Two-dimensional anion-rich NaCl<inf>2</inf> crystal under ambient conditions...\n",
      "Collected: Antimicrobial properties of Graphene sheets embedded with Titanium Oxide and Calcium Oxide nanoparti...\n",
      "Collected: Fabrication of promising competitive graphene nanocomposite transducer to determine Prucalopride suc...\n",
      "Collected: Retraction Note: Functionalized graphene oxide nanosheets with folic acid and silk fibroin as a nove...\n",
      "Collected: Significance of Marangoni convection in ethylene glycol base hybrid nanofluid flow with viscous diss...\n",
      "Collected: Amelioration of the growth and physiological responses of Capsicum annum L. via quantum dot-graphene...\n",
      "Collected: Reconfigurable and nonvolatile ferroelectric bulk photovoltaics based on 3R-WS<inf>2</inf> for machi...\n",
      "Collected: Floatable artificial leaf to couple oxygen-tolerant CO<inf>2</inf> conversion with water purificatio...\n",
      "Collected: Mechanistic evaluation of enhanced graphene toxicity to Bacillus induced by humic acid adsorption...\n",
      "Collected: Unveiling antidiabetic and antioxidant activities of biogenically synthesized red fluorescent graphe...\n",
      "Collected: Remote epitaxy and exfoliation of vanadium dioxide via sub-nanometer thick amorphous interlayer...\n",
      "Collected: High-entropy alloys catalyzing polymeric transformation of water pollutants with remarkably improved...\n",
      "Collected: Antiferromagnetic semimetal terahertz photodetectors enhanced through weak localization...\n",
      "Collected: Modeling and Simulation of Quantum State Distribution in Graphene Nanoribbon GaN/InSb TFETs for High...\n",
      "Collected: A Fully-Printed Wearable Bandage-Based Electrochemical Sensor with pH Correction for Wound Infection...\n",
      "Collected: Formation of bone tissue apatite on starch-based nanofiber-capped nanohydroxyapatite and reduced gra...\n",
      "Collected: Integration of Electrical Properties and Polarization Loss Modulation on Atomic Feâ€“N-RGO for Boostin...\n",
      "Collected: Flexible Graphene Field-Effect Transistors and Their Application in Flexible Biomedical Sensing...\n",
      "Collected: Advances in Graphene-Based Electrode for Triboelectric Nanogenerator...\n",
      "Collected: Far-field ammonia gas sensing at room temperature with graphene nanoplatelets-infused PEDOT:PSS tran...\n",
      "Collected: Tryptophan-functionalized fullerene C<inf>60</inf> anchored on graphene oxide as a breakthrough in s...\n",
      "Collected: Application of S-type heterojunction CaTiO<inf>3</inf>/rGO-g-C<inf>3</inf>N<inf>4</inf> photocatalys...\n",
      "Collected: Free-Standing Ni nanoparticles wrapped in electrochemically reduced graphene Oxide: A highly efficie...\n",
      "\n",
      "Fetching batch 2 (records 26 to 50)...\n",
      "Found 25 papers in this batch (Total available: 94883)\n",
      "Collected: Pore optimization engineering for enhancing ion storage and capacitive deionization properties of gr...\n",
      "Collected: 3D-Printed SiOC Ceramics Grafted with Chitosan-Graphene Oxide Composite for Enhanced Dye Adsorption...\n",
      "Collected: Simultaneous adsorption and two-dimensional confined mass transfer separation of iodide ions by a no...\n",
      "Collected: Removal of chlorpheniramine maleate by electrochemical reduction at Pd/CGC/Al<inf>2</inf>O<inf>3</in...\n",
      "Collected: Designing PMIA/MOF nanofiber membranes for heat-resistant nanofiltration and its application in dye/...\n",
      "Collected: Scalable fabrication of graphene-basalt composite fabric via Layer-by-Layer deposition for efficient...\n",
      "Collected: Development of the DES-contained reduced graphene oxide system with efficient CO<inf>2</inf> adsorpt...\n",
      "Collected: High-performance photo-self-Fenton control of antibiotic resistance contamination in water mediated ...\n",
      "Collected: Sustainable carbonaceous materials-based catalytic membranes for organic wastewater treatment: Progr...\n",
      "Collected: A comprehensive review on ionic liquids and ionic hybrid materials for CO<inf>2</inf> separation...\n",
      "Collected: A critical review on graphene-based membrane for ion separation: Mechanisms, research status, and de...\n",
      "Collected: Enhancing photothermal conversion efficiency and aqueous stability of graphene oxide membranes for c...\n",
      "Collected: Janus structured carbon-graphene composite aerogel for high efficiency solar water evaporation...\n",
      "Collected: Construction process optimisation of graphene-basalt fibre asphalt mixtures...\n",
      "Collected: Nanomodification analysis of pore structure in GO-enhanced CWRB based on metal intrusion and BSE ima...\n",
      "Collected: Influence of the graphene oxide on heat conduction characteristics of cement-based honeycomb scaffol...\n",
      "Collected: SnO<inf>2</inf>[sbnd]SnS<inf>2</inf>/graphene heterojunction composite promotes high-performance sod...\n",
      "Collected: Preparation of post-synthetized MOF-303@ graphene oxide (GO) composite membrane for pervaporative de...\n",
      "Collected: Hollow carbon nanocone arrays on carbon fiber cloth as a free-standing electrode for high-performanc...\n",
      "Collected: Charge transfer and interfacial binding strategy: Enhancing photocatalytic CO<inf>2</inf> reduction ...\n",
      "Collected: Study on preparation of a pizza-like attapulgite-based composite membrane and its performance on met...\n",
      "Collected: Intelligent marine waterborne epoxy coating based on functionalized multiscale nanocomposite: Mechan...\n",
      "Collected: Prewetting induced underwater super oleophobic hydroxyethyl cellulose-SiO<inf>2</inf>-graphene micro...\n",
      "Collected: Molecular separation applications of next-generation graphene oxide composite membranes with enhance...\n",
      "Collected: Fabrication and separation performances of composite membranes containing copper ferrite photocataly...\n",
      "\n",
      "Saving data...\n",
      "Successfully saved 50 papers to /Users/adamgeorghiou/Desktop/GIM/Project/data/raw/scopus_papers.csv\n",
      "Saved summary version to /Users/adamgeorghiou/Desktop/GIM/Project/data/raw/scopus_papers_summary.csv\n",
      "\n",
      "Collection Summary:\n",
      "Total papers collected: 50\n",
      "Date range: 2025-06-07 to 2025-12-01\n",
      "\n",
      "Citation Statistics:\n",
      "Total citations: 50\n",
      "Average citations per paper: 1.00\n",
      "Most cited paper: Advances in Graphene-Based Electrode for Triboelectric Nanogenerator (36 citations)\n",
      "\n",
      "Top Journals:\n",
      "journal\n",
      "Separation and Purification Technology    23\n",
      "Nature Communications                      7\n",
      "Scientific Reports                         4\n",
      "Nano-Micro Letters                         4\n",
      "Case Studies in Construction Materials     3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top Authors:\n",
      "Yang Wang           2\n",
      "Yanming Liu         2\n",
      "Hao Li              2\n",
      "Yuan Gao            2\n",
      "Safaa A. Hussein    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# scopus_collector.py\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Create necessary directories\n",
    "DATA_DIR = '/Users/adamgeorghiou/Desktop/GIM/Project/data/raw'\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    filename='scopus_collection.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "class ScopusCollector:\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "        self.api_key = os.getenv('SCOPUS_API_KEY')\n",
    "        self.base_url = \"https://api.elsevier.com/content/search/scopus\"\n",
    "        self.headers = {\n",
    "            'X-ELS-APIKey': self.api_key,\n",
    "            'Accept': 'application/json'\n",
    "        }\n",
    "        \n",
    "    def search_papers(self, num_results=50):\n",
    "        \"\"\"\n",
    "        Search Scopus for graphene-related papers\n",
    "        \"\"\"\n",
    "        if not self.api_key:\n",
    "            print(\"Scopus API key not found. Please set SCOPUS_API_KEY environment variable.\")\n",
    "            return\n",
    "            \n",
    "        print(f\"Searching Scopus for: graphene applications\")\n",
    "        print(f\"Using API key: {self.api_key[:5]}...\")\n",
    "        \n",
    "        try:\n",
    "            # Scopus allows up to 25 results per query\n",
    "            batch_size = 25\n",
    "            for start in range(0, num_results, batch_size):\n",
    "                params = {\n",
    "                    'query': 'TITLE-ABS-KEY(graphene applications)',\n",
    "                    'count': min(batch_size, num_results - start),\n",
    "                    'start': start,\n",
    "                    'sort': '-coverDate',\n",
    "                    'view': 'COMPLETE'  # Get complete record information\n",
    "                }\n",
    "                \n",
    "                print(f\"\\nFetching batch {start//batch_size + 1} (records {start+1} to {start+batch_size})...\")\n",
    "                \n",
    "                response = requests.get(\n",
    "                    self.base_url,\n",
    "                    headers=self.headers,\n",
    "                    params=params\n",
    "                )\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    entries = data.get('search-results', {}).get('entry', [])\n",
    "                    total_results = int(data.get('search-results', {}).get('opensearch:totalResults', 0))\n",
    "                    \n",
    "                    print(f\"Found {len(entries)} papers in this batch (Total available: {total_results})\")\n",
    "                    \n",
    "                    for entry in entries:\n",
    "                        try:\n",
    "                            # Extract authors (if available)\n",
    "                            authors = entry.get('author', [])\n",
    "                            author_names = [f\"{author.get('given-name', '')} {author.get('surname', '')}\" \n",
    "                                          for author in authors]\n",
    "                            \n",
    "                            paper_data = {\n",
    "                                'title': entry.get('dc:title', ''),\n",
    "                                'authors': '; '.join(author_names),\n",
    "                                'abstract': entry.get('dc:description', ''),\n",
    "                                'published_date': entry.get('prism:coverDate', ''),\n",
    "                                'doi': entry.get('prism:doi', ''),\n",
    "                                'journal': entry.get('prism:publicationName', ''),\n",
    "                                'volume': entry.get('prism:volume', ''),\n",
    "                                'issue': entry.get('prism:issueIdentifier', ''),\n",
    "                                'pages': entry.get('prism:pageRange', ''),\n",
    "                                'citations': int(entry.get('citedby-count', 0)),\n",
    "                                'keywords': entry.get('authkeywords', ''),\n",
    "                                'url': entry.get('prism:url', ''),\n",
    "                                'collection_date': datetime.now().isoformat(),\n",
    "                                'source': 'Scopus'\n",
    "                            }\n",
    "                            \n",
    "                            self.data.append(paper_data)\n",
    "                            print(f\"Collected: {paper_data['title'][:100]}...\")\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing paper: {str(e)}\")\n",
    "                            continue\n",
    "                            \n",
    "                elif response.status_code == 401:\n",
    "                    print(\"Authentication Error (401). Please verify your API key is correct and active\")\n",
    "                    print(f\"Response: {response.text}\")\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"Error: API returned status code {response.status_code}\")\n",
    "                    print(f\"Response: {response.text}\")\n",
    "                    break\n",
    "                    \n",
    "                # Rate limiting - Scopus allows 6 requests per second\n",
    "                time.sleep(0.2)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in search: {str(e)}\")\n",
    "            logging.error(f\"Error in search: {str(e)}\")\n",
    "            \n",
    "    def save_data(self, filename='scopus_papers.csv'):\n",
    "        \"\"\"\n",
    "        Save collected data to CSV\n",
    "        \"\"\"\n",
    "        if not self.data:\n",
    "            print(\"No data to save!\")\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            df = pd.DataFrame(self.data)\n",
    "            output_path = os.path.join(DATA_DIR, filename)\n",
    "            df.to_csv(output_path, index=False)\n",
    "            print(f\"Successfully saved {len(self.data)} papers to {output_path}\")\n",
    "            \n",
    "            # Save a summary version with key fields\n",
    "            summary_df = df[['title', 'authors', 'published_date', 'journal', 'citations', 'url']]\n",
    "            summary_path = os.path.join(DATA_DIR, 'scopus_papers_summary.csv')\n",
    "            summary_df.to_csv(summary_path, index=False)\n",
    "            print(f\"Saved summary version to {summary_path}\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error saving data: {str(e)}\")\n",
    "            return None\n",
    "            \n",
    "    def analyze_data(self, df):\n",
    "        \"\"\"\n",
    "        Analyze the collected data\n",
    "        \"\"\"\n",
    "        if df is None or df.empty:\n",
    "            return\n",
    "            \n",
    "        print(\"\\nCollection Summary:\")\n",
    "        print(f\"Total papers collected: {len(df)}\")\n",
    "        \n",
    "        # Date range\n",
    "        df['published_date'] = pd.to_datetime(df['published_date'])\n",
    "        print(f\"Date range: {df['published_date'].min().date()} to {df['published_date'].max().date()}\")\n",
    "        \n",
    "        # Citation statistics with error handling\n",
    "        print(f\"\\nCitation Statistics:\")\n",
    "        try:\n",
    "            # Clean citations data - remove any non-numeric values\n",
    "            df['citations'] = pd.to_numeric(df['citations'], errors='coerce')\n",
    "            df['citations'] = df['citations'].fillna(0).astype(int)\n",
    "            \n",
    "            total_citations = df['citations'].sum()\n",
    "            avg_citations = df['citations'].mean()\n",
    "            \n",
    "            print(f\"Total citations: {total_citations:,}\")\n",
    "            print(f\"Average citations per paper: {avg_citations:.2f}\")\n",
    "            \n",
    "            if len(df) > 0:\n",
    "                most_cited_idx = df['citations'].idxmax()\n",
    "                most_cited_title = df.loc[most_cited_idx, 'title']\n",
    "                most_cited_count = df.loc[most_cited_idx, 'citations']\n",
    "                print(f\"Most cited paper: {most_cited_title} ({most_cited_count:,} citations)\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing citation statistics: {str(e)}\")\n",
    "        \n",
    "        # Journal statistics\n",
    "        print(f\"\\nTop Journals:\")\n",
    "        print(df['journal'].value_counts().head())\n",
    "        \n",
    "        # Author statistics\n",
    "        all_authors = [author.strip() for authors in df['authors'].str.split(';') for author in authors if author.strip()]\n",
    "        top_authors = pd.Series(all_authors).value_counts().head()\n",
    "        print(f\"\\nTop Authors:\")\n",
    "        print(top_authors)\n",
    "\n",
    "def main():\n",
    "    collector = ScopusCollector()\n",
    "    \n",
    "    print(\"Starting Scopus data collection...\")\n",
    "    collector.search_papers(num_results=50)\n",
    "    \n",
    "    print(\"\\nSaving data...\")\n",
    "    df = collector.save_data()\n",
    "    \n",
    "    if df is not None:\n",
    "        collector.analyze_data(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
