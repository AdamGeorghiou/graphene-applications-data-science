{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data collection...\n",
      "Searching arXiv for: graphene applications\n",
      "Fetching data from arXiv...\n",
      "Found 50 papers\n",
      "Successfully collected paper: Hydrogenated-Graphene encapsulated Graphene: A versatile material for   device applications...\n",
      "Successfully collected paper: Determining Graphene Adhesion via Substrate-regulated Morphology of   Graphene...\n",
      "Successfully collected paper: Graphene-plasmon polaritons: From fundamental properties to potential   applications...\n",
      "Successfully collected paper: Crystal orientation relation and macroscopic surface roughness in   hetero-epitaxially grown graphen...\n",
      "Successfully collected paper: Quantifying Mn diffusion through transferred versus directly-grown   graphene barriers...\n",
      "Successfully collected paper: Graphene Field Effect Transistors: A Review...\n",
      "Successfully collected paper: Growth and electronic structure of graphene on semiconducting Ge(110)...\n",
      "Successfully collected paper: Graphene MEMS and NEMS...\n",
      "Successfully collected paper: Three-dimensional porous graphene networks expand graphene-based   electronic device applications...\n",
      "Successfully collected paper: Phononics of Graphene and Graphene Composites...\n",
      "Successfully collected paper: Contrasting diffusion behaviors of O and F atoms on graphene and within   bilayer graphene...\n",
      "Successfully collected paper: Graphene Helicoid: The Distinct Properties Promote Application of   Graphene Related Materials in Th...\n",
      "Successfully collected paper: Magnetism in Graphene Systems...\n",
      "Successfully collected paper: Tuneable electronic properties in graphene...\n",
      "Successfully collected paper: Synthesis of Graphene on Gold...\n",
      "Successfully collected paper: Optical absorption in graphene integrated on silicon waveguides...\n",
      "Successfully collected paper: Graphene plasmonics...\n",
      "Successfully collected paper: Directional excitation of graphene surface plasmons...\n",
      "Successfully collected paper: Mass measurement of graphene using quartz crystal microbalances...\n",
      "Successfully collected paper: Transfer-free fabrication of graphene transistors...\n",
      "Successfully collected paper: Organometallic Complexes of Graphene...\n",
      "Successfully collected paper: Multilayer graphene shows intrinsic resistance peaks in the carrier   density dependence...\n",
      "Successfully collected paper: Localized in-situ polymerization on graphene surfaces for stabilized   graphene dispersions...\n",
      "Successfully collected paper: Biocompatibility of Pristine Graphene Monolayers, Nanosheets and Thin   Films...\n",
      "Successfully collected paper: Raman spectroscopy and imaging of graphene...\n",
      "Successfully collected paper: Solvothermal Reduction of Chemically Exfoliated Graphene Sheets...\n",
      "Successfully collected paper: Electromagnetic waves reflection, transmission and absorption by   graphene - magnetic semiconductor...\n",
      "Successfully collected paper: Graphene growth and properties on metal substrates...\n",
      "Successfully collected paper: Buckled Graphene for Efficient Energy Harvest, Storage, and Conversion...\n",
      "Successfully collected paper: Atmosphere Pressure Chemical Vapor Deposition of Graphene...\n",
      "Successfully collected paper: Production, properties and potential of graphene...\n",
      "Successfully collected paper: The Inherent Behavior of Graphene Flakes in Water: A Molecular Dynamics   Study...\n",
      "Successfully collected paper: Reversible doping of graphene field effect transistors by molecular   hydrogen: the role of the meta...\n",
      "Successfully collected paper: Gas Barrier Performance of Graphene/Polymer Nanocomposites...\n",
      "Successfully collected paper: Enhancing visibility of graphene on arbitrary substrates by microdroplet   condensation...\n",
      "Successfully collected paper: Electrostatic deposition of graphene in a gaseous environment: A   deterministic route to synthesize...\n",
      "Successfully collected paper: Tuning of Graphene Properties via Controlled Exposure to Electron Beams...\n",
      "Successfully collected paper: Extrinsic morphology of graphene...\n",
      "Successfully collected paper: The tuning of light-matter coupling and dichroism in graphene for   enhanced absorption: Implication...\n",
      "Successfully collected paper: Layer compression and enhanced optical properties of few-layer graphene   nanosheets induced by ion ...\n",
      "Successfully collected paper: Rapid characterization of wafer-scale 2D material: Epitaxial graphene   and graphene nanoribbons on ...\n",
      "Successfully collected paper: On the Use of Graphene to Improve the Performance of Concentrator III-V   Multijunction Solar Cells...\n",
      "Successfully collected paper: Dry-transferred CVD graphene for inverted spin valve devices...\n",
      "Successfully collected paper: A Graphene-Carbon Nanotube Hybrid Material for Photovoltaic Applications...\n",
      "Successfully collected paper: Graphene Field Effect Transistors: Diffusion-Drift Theory...\n",
      "Successfully collected paper: Atomic layer deposition of high-k oxides on graphene...\n",
      "Successfully collected paper: Opening of a Gap in Graphene Due to Supercell Potential: Group Theory   Point of View...\n",
      "Successfully collected paper: Strong terahertz response in bilayer graphene nanoribbons...\n",
      "Successfully collected paper: How the SiC substrate impacts graphene atomic and electronic structures...\n",
      "Successfully collected paper: 100 GHz Transistors from Wafer Scale Epitaxial Graphene...\n",
      "\n",
      "Saving data...\n",
      "Successfully saved 50 papers to /Users/adamgeorghiou/Desktop/GIM/Project/data/raw/arxiv/arxiv_papers.csv\n",
      "Saved summary version to /Users/adamgeorghiou/Desktop/GIM/Project/data/raw/arxiv/arxiv_papers_summary.csv\n",
      "\n",
      "Analyzing results...\n",
      "Data collection summary: {'total_papers': 50, 'date_range': '2008-07-11 - 2024-10-02', 'unique_categories': 9, 'unique_authors': 213, 'top_categories': {'cond-mat.mtrl-sci': 30, 'cond-mat.mes-hall': 26, 'physics.optics': 5, 'physics.app-ph': 5, 'cond-mat.other': 1}}\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Create necessary directories\n",
    "DATA_DIR = '/Users/adamgeorghiou/Desktop/GIM/Project/data/raw/arxiv'\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Create logs directory if it doesn't exist\n",
    "LOGS_DIR = '/Users/adamgeorghiou/Desktop/GIM/Project/logs'\n",
    "os.makedirs(LOGS_DIR, exist_ok=True)\n",
    "\n",
    "class GrapheneResearchCollector:\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "        self.base_url = \"http://export.arxiv.org/api/query\"\n",
    "        \n",
    "        # Set up logger\n",
    "        self.logger = logging.getLogger('arxiv_collector')\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        \n",
    "        # Create file handler\n",
    "        fh = logging.FileHandler(os.path.join(LOGS_DIR, 'arxiv_collection.log'))\n",
    "        fh.setLevel(logging.INFO)\n",
    "        \n",
    "        # Create formatter\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        fh.setFormatter(formatter)\n",
    "        \n",
    "        # Add handler to logger\n",
    "        self.logger.addHandler(fh)\n",
    "        \n",
    "        # Prevent logging from being passed to the root logger\n",
    "        self.logger.propagate = False\n",
    "        \n",
    "    def search_papers(self, num_results=100):\n",
    "        \"\"\"\n",
    "        Search arXiv for graphene-related papers using urllib\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"Starting search for {num_results} papers\")\n",
    "        query = urllib.parse.quote(\"graphene applications\")\n",
    "        print(f\"Searching arXiv for: graphene applications\")\n",
    "        \n",
    "        try:\n",
    "            # Format the query URL\n",
    "            query_url = f\"{self.base_url}?search_query=all:{query}&start=0&max_results={num_results}\"\n",
    "            \n",
    "            print(\"Fetching data from arXiv...\")\n",
    "            with urllib.request.urlopen(query_url) as response:\n",
    "                response_data = response.read()\n",
    "            \n",
    "            # Parse XML response\n",
    "            root = ET.fromstring(response_data)\n",
    "            \n",
    "            # ArXiv XML uses namespaces\n",
    "            namespace = {'atom': 'http://www.w3.org/2005/Atom',\n",
    "                        'arxiv': 'http://arxiv.org/schemas/atom'}\n",
    "            \n",
    "            entries = root.findall('atom:entry', namespace)\n",
    "            print(f\"Found {len(entries)} papers\")\n",
    "            self.logger.info(f\"Found {len(entries)} papers\")\n",
    "            \n",
    "            for entry in entries:\n",
    "                try:\n",
    "                    # Extract data from XML\n",
    "                    title = entry.find('atom:title', namespace).text.strip().replace('\\n', ' ')\n",
    "                    abstract = entry.find('atom:summary', namespace).text.strip().replace('\\n', ' ')\n",
    "                    published = entry.find('atom:published', namespace).text\n",
    "                    \n",
    "                    # Get authors\n",
    "                    authors = [author.find('atom:name', namespace).text \n",
    "                            for author in entry.findall('atom:author', namespace)]\n",
    "                    \n",
    "                    # Get categories\n",
    "                    categories = [cat.get('term') \n",
    "                                for cat in entry.findall('atom:category', namespace)]\n",
    "                    \n",
    "                    paper_data = {\n",
    "                        'title': title,\n",
    "                        'authors': ', '.join(authors),\n",
    "                        'abstract': abstract,\n",
    "                        'published_date': published,\n",
    "                        'url': entry.find('atom:id', namespace).text,\n",
    "                        'categories': ', '.join(categories),\n",
    "                        'collection_date': datetime.now().isoformat(),\n",
    "                        'source': 'arXiv'\n",
    "                    }\n",
    "                    \n",
    "                    self.data.append(paper_data)\n",
    "                    self.logger.info(f\"Collected paper: {title[:100]}\")\n",
    "                    print(f\"Successfully collected paper: {title[:100]}...\")\n",
    "                    \n",
    "                    # Small delay between processing entries\n",
    "                    time.sleep(0.1)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    error_msg = f\"Error processing paper: {str(e)}\"\n",
    "                    print(error_msg)\n",
    "                    self.logger.error(error_msg)\n",
    "                    continue\n",
    "                    \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error in search: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            self.logger.error(error_msg)\n",
    "            \n",
    "    def save_data(self, filename='arxiv_papers.csv'):\n",
    "        \"\"\"\n",
    "        Save collected data to CSV\n",
    "        \"\"\"\n",
    "        if not self.data:\n",
    "            msg = \"No data to save!\"\n",
    "            print(msg)\n",
    "            self.logger.warning(msg)\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            df = pd.DataFrame(self.data)\n",
    "            output_path = os.path.join(DATA_DIR, filename)\n",
    "            df.to_csv(output_path, index=False)\n",
    "            msg = f\"Successfully saved {len(self.data)} papers to {output_path}\"\n",
    "            print(msg)\n",
    "            self.logger.info(msg)\n",
    "            \n",
    "            # Save a more readable summary version\n",
    "            summary_df = df[['title', 'authors', 'published_date', 'categories', 'url']]\n",
    "            summary_path = os.path.join(DATA_DIR, 'arxiv_papers_summary.csv')\n",
    "            summary_df.to_csv(summary_path, index=False)\n",
    "            msg = f\"Saved summary version to {summary_path}\"\n",
    "            print(msg)\n",
    "            self.logger.info(msg)\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error saving data: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            self.logger.error(error_msg)\n",
    "        \n",
    "    def analyze_initial_data(self):\n",
    "        \"\"\"\n",
    "        Basic analysis of collected data\n",
    "        \"\"\"\n",
    "        if not self.data:\n",
    "            return {\"status\": \"No data collected\"}\n",
    "            \n",
    "        try:\n",
    "            df = pd.DataFrame(self.data)\n",
    "            \n",
    "            # Convert published_date to datetime\n",
    "            df['published_date'] = pd.to_datetime(df['published_date'])\n",
    "            \n",
    "            summary = {\n",
    "                'total_papers': len(df),\n",
    "                'date_range': f\"{df['published_date'].min().date()} - {df['published_date'].max().date()}\",\n",
    "                'unique_categories': len(set([cat for cats in df['categories'].str.split(', ') for cat in cats])),\n",
    "                'unique_authors': len(set([author for authors in df['authors'].str.split(', ') for author in authors]))\n",
    "            }\n",
    "            \n",
    "            # Get top categories\n",
    "            all_categories = [cat for cats in df['categories'].str.split(', ') for cat in cats]\n",
    "            top_categories = pd.Series(all_categories).value_counts().head(5).to_dict()\n",
    "            summary['top_categories'] = top_categories\n",
    "            \n",
    "            self.logger.info(f\"Analysis complete: {summary}\")\n",
    "            return summary\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error in analysis: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            self.logger.error(error_msg)\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "def main():\n",
    "    collector = GrapheneResearchCollector()\n",
    "    \n",
    "    print(\"Starting data collection...\")\n",
    "    collector.search_papers(num_results=50)  # Start with 50 papers\n",
    "    \n",
    "    print(\"\\nSaving data...\")\n",
    "    collector.save_data()\n",
    "    \n",
    "    print(\"\\nAnalyzing results...\")\n",
    "    summary = collector.analyze_initial_data()\n",
    "    print(\"Data collection summary:\", summary)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
