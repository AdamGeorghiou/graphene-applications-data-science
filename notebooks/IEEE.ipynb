{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting IEEE data collection...\n",
      "Searching IEEE Xplore for: graphene applications\n",
      "Using API key: z3fen...\n",
      "\n",
      "Fetching batch 1 (records 1 to 10)...\n",
      "Authentication Error (403). Full response:\n",
      "URL: http://ieeexploreapi.ieee.org/api/v1/search/articles?apikey=z3fencvfv77wmnwxp9m74ju8&querytext=graphene+applications&max_records=10&start_record=1&sort_order=desc&sort_field=publication_year&abstract=true\n",
      "Response: <h1>Developer Inactive</h1>\n",
      "Please verify your API key is correct and active\n",
      "\n",
      "Saving data...\n",
      "No data to save!\n"
     ]
    }
   ],
   "source": [
    "# ieee_collector.py\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Create necessary directories\n",
    "DATA_DIR = '/Users/adamgeorghiou/Desktop/GIM/Project/data/raw'\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    filename='ieee_collection.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "class IEEECollector:\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "        self.api_key = os.getenv('IEEE_API_KEY')\n",
    "        self.base_url = \"http://ieeexploreapi.ieee.org/api/v1/search/articles\"\n",
    "        self.calls_made = 0\n",
    "        self.last_call_time = None\n",
    "        \n",
    "    def _wait_for_rate_limit(self):\n",
    "        \"\"\"Implement rate limiting\"\"\"\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # If this is not the first call, check the time since last call\n",
    "        if self.last_call_time is not None:\n",
    "            elapsed = current_time - self.last_call_time\n",
    "            if elapsed < 0.1:  # Ensure at least 100ms between calls (10 calls per second limit)\n",
    "                time.sleep(0.1 - elapsed)\n",
    "        \n",
    "        self.last_call_time = time.time()\n",
    "        self.calls_made += 1\n",
    "        \n",
    "        if self.calls_made >= 190:  # Conservative limit\n",
    "            print(\"Approaching daily rate limit, stopping collection\")\n",
    "            return False\n",
    "        return True\n",
    "        \n",
    "    def search_papers(self, num_results=50):\n",
    "        \"\"\"\n",
    "        Search IEEE Xplore for graphene-related papers\n",
    "        \"\"\"\n",
    "        if not self.api_key:\n",
    "            print(\"IEEE API key not found. Please set IEEE_API_KEY environment variable.\")\n",
    "            return\n",
    "            \n",
    "        print(f\"Searching IEEE Xplore for: graphene applications\")\n",
    "        print(f\"Using API key: {self.api_key[:5]}...\")  # Print first 5 chars for verification\n",
    "        \n",
    "        try:\n",
    "            # Split into smaller batches to handle rate limits\n",
    "            batch_size = 10\n",
    "            for start in range(0, num_results, batch_size):\n",
    "                if not self._wait_for_rate_limit():\n",
    "                    break\n",
    "                    \n",
    "                params = {\n",
    "                    'apikey': self.api_key,\n",
    "                    'querytext': 'graphene applications',\n",
    "                    'max_records': min(batch_size, num_results - start),\n",
    "                    'start_record': start + 1,\n",
    "                    'sort_order': 'desc',\n",
    "                    'sort_field': 'publication_year',\n",
    "                    'abstract': 'true'\n",
    "                }\n",
    "                \n",
    "                print(f\"\\nFetching batch {start//batch_size + 1} (records {start+1} to {start+batch_size})...\")\n",
    "                \n",
    "                response = requests.get(self.base_url, params=params)\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    articles = data.get('articles', [])\n",
    "                    total_found = data.get('total_records', 0)\n",
    "                    \n",
    "                    print(f\"Found {len(articles)} papers in this batch\")\n",
    "                    \n",
    "                    for article in articles:\n",
    "                        try:\n",
    "                            authors = article.get('authors', {'authors': []}).get('authors', [])\n",
    "                            author_names = [f\"{author.get('full_name', '')}\" for author in authors]\n",
    "                            \n",
    "                            paper_data = {\n",
    "                                'title': article.get('title', ''),\n",
    "                                'authors': '; '.join(author_names),\n",
    "                                'abstract': article.get('abstract', ''),\n",
    "                                'published_date': article.get('publication_date', ''),\n",
    "                                'doi': article.get('doi', ''),\n",
    "                                'publisher': article.get('publisher', ''),\n",
    "                                'document_type': article.get('content_type', ''),\n",
    "                                'conference': article.get('conference_location', ''),\n",
    "                                'citations': article.get('citing_paper_count', 0),\n",
    "                                'keywords': '; '.join(article.get('index_terms', {}).get('ieee_terms', {}).get('terms', [])),\n",
    "                                'url': f\"https://doi.org/{article.get('doi', '')}\" if article.get('doi') else '',\n",
    "                                'collection_date': datetime.now().isoformat(),\n",
    "                                'source': 'IEEE'\n",
    "                            }\n",
    "                            \n",
    "                            self.data.append(paper_data)\n",
    "                            print(f\"Collected: {paper_data['title'][:100]}...\")\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing paper: {str(e)}\")\n",
    "                            continue\n",
    "                            \n",
    "                elif response.status_code == 403:\n",
    "                    print(f\"Authentication Error (403). Full response:\")\n",
    "                    print(f\"URL: {response.url}\")\n",
    "                    print(f\"Response: {response.text}\")\n",
    "                    print(\"Please verify your API key is correct and active\")\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"Error: API returned status code {response.status_code}\")\n",
    "                    print(f\"Response: {response.text}\")\n",
    "                    break\n",
    "                    \n",
    "                # Wait between batches\n",
    "                time.sleep(1)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in search: {str(e)}\")\n",
    "            logging.error(f\"Error in search: {str(e)}\")\n",
    "            \n",
    "    def save_data(self, filename='ieee_papers.csv'):\n",
    "        \"\"\"\n",
    "        Save collected data to CSV\n",
    "        \"\"\"\n",
    "        if not self.data:\n",
    "            print(\"No data to save!\")\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            df = pd.DataFrame(self.data)\n",
    "            output_path = os.path.join(DATA_DIR, filename)\n",
    "            df.to_csv(output_path, index=False)\n",
    "            print(f\"Successfully saved {len(self.data)} papers to {output_path}\")\n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error saving data: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "def main():\n",
    "    collector = IEEECollector()\n",
    "    \n",
    "    print(\"Starting IEEE data collection...\")\n",
    "    collector.search_papers(num_results=50)\n",
    "    \n",
    "    print(\"\\nSaving data...\")\n",
    "    df = collector.save_data()\n",
    "    \n",
    "    if df is not None:\n",
    "        print(\"\\nCollection Summary:\")\n",
    "        print(f\"Total papers collected: {len(df)}\")\n",
    "        if len(df) > 0:\n",
    "            print(f\"Date range: {df['published_date'].min()} to {df['published_date'].max()}\")\n",
    "            print(f\"Document types: {df['document_type'].value_counts().to_dict()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key: z3fencvfv77wmnwxp9m74ju8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "load_dotenv()\n",
    "print(f\"API Key: {os.getenv('IEEE_API_KEY', 'Not found')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
